{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Imputation Redux: Imputing Missing Categorical Data\n",
    "\n",
    "Categorical data presents a particular kind of challenge, because (as we discussed) sklearn doesn't like to deal with non-numeric data. For instance, the KNNImputer will fail if we attempt to encode categorical values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error when trying to impute:\n",
      "could not convert string to float: 'High School'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic data\n",
    "n_samples = 100\n",
    "age = np.random.randint(18, 80, n_samples)\n",
    "income = np.random.randint(20000, 100000, n_samples)\n",
    "education = np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples)\n",
    "city = np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Miami'], n_samples)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Age': age,\n",
    "    'Income': income,\n",
    "    'Education': education,\n",
    "    'City': city\n",
    "})\n",
    "\n",
    "# Introduce missing values\n",
    "for column in df.columns:\n",
    "    mask = np.random.choice([True, False], size=df.shape[0], p=[0.1, 0.9])\n",
    "    df.loc[mask, column] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Try to use KNNImputer on the entire DataFrame\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "try:\n",
    "    imputed_data = imputer.fit_transform(df)\n",
    "    print(\"\\nImputed data:\")\n",
    "    print(imputed_data[:10])\n",
    "except ValueError as e:\n",
    "    print(\"\\nError when trying to impute:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two strategies for dealing with this; we can use SKLearn's \"most frequent\" method for Simple Imputation.  Alternatively (if we want to use something like a KNNImputer) we'll need to encode the data first, and then impute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Using Pandas or Most Frequent Category\n",
    "\n",
    "You can use pandas to replace nulls, using one of the methods we covered previously. Alternatively, you can use SimpleImputer with the `strategy='most_frequent'` option to impute missing values with the most frequent category in each column before one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Education</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57065.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52606.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>31534.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>60397.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21016.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>46.0</td>\n",
       "      <td>54766.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>93530.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>43.0</td>\n",
       "      <td>81087.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>51.0</td>\n",
       "      <td>74384.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age   Income    Education         City\n",
       "0    NaN  57065.0       Master     New York\n",
       "1    NaN  52606.0  High School  Los Angeles\n",
       "2   46.0  31534.0     Bachelor     New York\n",
       "3   32.0  60397.0          PhD      Houston\n",
       "4    NaN  21016.0          PhD        Miami\n",
       "..   ...      ...          ...          ...\n",
       "95  46.0  54766.0     Bachelor     New York\n",
       "96  35.0  93530.0          PhD      Chicago\n",
       "97  43.0  81087.0  High School     New York\n",
       "98   NaN  88840.0          PhD     New York\n",
       "99  51.0  74384.0          PhD     New York\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_imputed = df.copy()\n",
    "# Impute missing values\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "df_imputed[[\"Education\",\"City\"]] = imp.fit_transform(df[['Education','City']])\n",
    "df_imputed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding and then imputing\n",
    "\n",
    "If we wanted to use something more sophisticated, like a KNNImputer, we might think we try to encode first, and then impute, but there is another subtle problem here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Education</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.2</td>\n",
       "      <td>57065.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.4</td>\n",
       "      <td>52606.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>31534.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>60397.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.2</td>\n",
       "      <td>21016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>46.0</td>\n",
       "      <td>54766.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35.0</td>\n",
       "      <td>93530.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>43.0</td>\n",
       "      <td>81087.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>50.2</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>51.0</td>\n",
       "      <td>74384.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age   Income  Education  City\n",
       "0   56.2  57065.0        1.2   4.0\n",
       "1   60.4  52606.0        1.0   2.0\n",
       "2   46.0  31534.0        0.0   4.0\n",
       "3   32.0  60397.0        3.0   1.0\n",
       "4   50.2  21016.0        3.0   3.0\n",
       "..   ...      ...        ...   ...\n",
       "95  46.0  54766.0        0.0   1.6\n",
       "96  35.0  93530.0        3.0   0.0\n",
       "97  43.0  81087.0        1.0   1.6\n",
       "98  50.2  88840.0        3.0   4.0\n",
       "99  51.0  74384.0        3.0   1.2\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "le_education = OrdinalEncoder()\n",
    "le_city = OrdinalEncoder()\n",
    "\n",
    "df_numeric = df.copy()\n",
    "# Fit and transform the non-null values\n",
    "df_numeric['Education'] = le_education.fit_transform(df[['Education']])\n",
    "df_numeric['City'] = le_city.fit_transform(df[['City']])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_data_numeric = imputer.fit_transform(df_numeric)\n",
    "\n",
    "# Create a new DataFrame with imputed values\n",
    "df_imputed = pd.DataFrame(imputed_data_numeric, columns=df.columns)\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Age        83 non-null     float64\n",
      " 1   Income     93 non-null     float64\n",
      " 2   Education  86 non-null     object \n",
      " 3   City       87 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the problem ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Education</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.2</td>\n",
       "      <td>57065.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>75591.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.8</td>\n",
       "      <td>43247.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38.0</td>\n",
       "      <td>44300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70.0</td>\n",
       "      <td>71214.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.0</td>\n",
       "      <td>33986.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38.0</td>\n",
       "      <td>32666.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>39.0</td>\n",
       "      <td>72972.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>66.0</td>\n",
       "      <td>50535.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>44.0</td>\n",
       "      <td>98603.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>50.8</td>\n",
       "      <td>83335.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>79.0</td>\n",
       "      <td>44538.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>72.0</td>\n",
       "      <td>26910.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>69.0</td>\n",
       "      <td>68297.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>20.0</td>\n",
       "      <td>70636.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>60.4</td>\n",
       "      <td>70015.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50.8</td>\n",
       "      <td>87214.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>43.0</td>\n",
       "      <td>69080.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>60.4</td>\n",
       "      <td>89163.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>45.0</td>\n",
       "      <td>68925.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>64.0</td>\n",
       "      <td>41976.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>23.0</td>\n",
       "      <td>41959.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>71.0</td>\n",
       "      <td>86199.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>46.0</td>\n",
       "      <td>54766.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>43.0</td>\n",
       "      <td>81087.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>51.0</td>\n",
       "      <td>74384.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age   Income  Education  City\n",
       "0   56.2  57065.0        1.2   4.0\n",
       "5   25.0  75591.0        1.2   3.0\n",
       "6   50.8  43247.0        2.0   1.4\n",
       "7   38.0  44300.0        0.0   1.6\n",
       "15  70.0  71214.0        1.2   0.0\n",
       "27  19.0  33986.0        1.2   0.0\n",
       "29  38.0  32666.0        3.0   1.6\n",
       "33  39.0  72972.2        2.4   4.0\n",
       "37  66.0  50535.0        2.0   1.0\n",
       "38  44.0  98603.0        1.2   4.0\n",
       "43  50.8  83335.0        3.0   1.4\n",
       "45  79.0  44538.0        3.0   1.0\n",
       "51  72.0  26910.0        1.2   3.0\n",
       "52  69.0  68297.2        2.0   1.0\n",
       "54  20.0  70636.0        1.2   1.6\n",
       "55  60.4  70015.0        1.2   1.0\n",
       "60  50.8  87214.0        2.0   1.4\n",
       "69  43.0  69080.0        2.0   1.6\n",
       "71  60.4  89163.0        1.2   1.0\n",
       "73  45.0  68925.0        1.2   1.0\n",
       "80  64.0  41976.0        1.2   2.0\n",
       "90  23.0  41959.0        0.0   1.8\n",
       "94  71.0  86199.0        1.2   2.0\n",
       "95  46.0  54766.0        0.0   1.6\n",
       "97  43.0  81087.0        1.0   1.6\n",
       "99  51.0  74384.0        3.0   1.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed[(df.Education.isna()) | (df.City.isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that KNN works by calculating the _mean_ of it's nearest neighbors.  That doesn't make much sense here.  We could round, but that defeats the purpose of using KNN.  One solution is to use a more robust library.  The following is a little advanced, but I've provided it hear so you can refer back.  For our purposes, a SimpleImputer should be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a Different Library!\n",
    "\n",
    "As you might imagine, others have struggled with this, and so there are other libraries designed to address this problem.  For instance, the `fancyimpute` package has both a KNNImputer and an IterativeImputer you might try.  Here's an example with the `KNNImputer` from `fancyimpute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fancyimpute\n",
      "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting knnimpute>=0.1.0 (from fancyimpute)\n",
      "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.2 in /home/codespace/.local/lib/python3.12/site-packages (from fancyimpute) (1.5.1)\n",
      "Collecting cvxpy (from fancyimpute)\n",
      "  Downloading cvxpy-1.5.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting cvxopt (from fancyimpute)\n",
      "  Downloading cvxopt-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting pytest (from fancyimpute)\n",
      "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting nose (from fancyimpute)\n",
      "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.12/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /home/codespace/.local/lib/python3.12/site-packages (from knnimpute>=0.1.0->fancyimpute) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\n",
      "Collecting osqp>=0.6.2 (from cvxpy->fancyimpute)\n",
      "  Downloading osqp-0.6.7.post1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting ecos>=2 (from cvxpy->fancyimpute)\n",
      "  Downloading ecos-2.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting clarabel>=0.5.0 (from cvxpy->fancyimpute)\n",
      "  Downloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting scs>=3.2.4.post1 (from cvxpy->fancyimpute)\n",
      "  Downloading scs-3.2.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting iniconfig (from pytest->fancyimpute)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from pytest->fancyimpute) (24.1)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->fancyimpute)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting qdldl (from osqp>=0.6.2->cvxpy->fancyimpute)\n",
      "  Downloading qdldl-0.1.7.post4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Downloading cvxopt-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cvxpy-1.5.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "Downloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ecos-2.0.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading osqp-0.6.7.post1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading scs-3.2.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading qdldl-0.1.7.post4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fancyimpute, knnimpute\n",
      "  Building wheel for fancyimpute (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29880 sha256=c4b95bb59b60cd80c96833dd4910ab1b65e10c59763da5d2770648fdb92d10ba\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/df/20/91/e4850b9a31cf660c1bc95515d3bcbc8010e869e5de6d5baf07\n",
      "  Building wheel for knnimpute (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11330 sha256=2110f0ed53f46af380e55a14ec997299b8334f6e91538e5309168c89e6557629\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/89/11/61/aa5a3167bfff49218cd043a73a83034b9eadd858b0059521be\n",
      "Successfully built fancyimpute knnimpute\n",
      "Installing collected packages: nose, pluggy, knnimpute, iniconfig, cvxopt, scs, qdldl, pytest, ecos, clarabel, osqp, cvxpy, fancyimpute\n",
      "Successfully installed clarabel-0.9.0 cvxopt-1.3.2 cvxpy-1.5.3 ecos-2.0.14 fancyimpute-0.7.0 iniconfig-2.0.0 knnimpute-0.1.0 nose-1.3.7 osqp-0.6.7.post1 pluggy-1.5.0 pytest-8.3.3 qdldl-0.1.7.post4 scs-3.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install fancyimpute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### FancyImputes K-Nearest Neighbors (KNN) Imputer\n",
    "\n",
    "KNN from fancyimputer won't work with categorical data directly, but instead of using the `mean` (which is used by SciKit Learn's KNNImputer) is uses the `mode` for imputation, which is what we want.  To use KNN, first you should first encode your data using an `OrdinalEncoder` or `LabelEncoder`, then impute, then transform your data back into the categorical values you want.  This is more complicated than it should be because there is no easy way to preserve nulls in your data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/6 with 0 missing, elapsed time: 0.001\n",
      "    Fruit   Color\n",
      "0   Apple     Red\n",
      "1  Banana  Yellow\n",
      "2  Cherry     Red\n",
      "3   Apple     Red\n",
      "4  Banana   Green\n",
      "5  Banana  Yellow\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create DataFrame with missing values\n",
    "data = {\n",
    "    'Fruit': ['Apple', 'Banana', 'Cherry', 'Apple', None, 'Banana'],\n",
    "    'Color': ['Red', 'Yellow', 'Red', None, 'Green', 'Yellow']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dictionary to hold LabelEncoders for each column\n",
    "encoders = {}\n",
    "\n",
    "# Replace categorical string values with numerical representations\n",
    "for col in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    not_null_mask = df[col].notnull()\n",
    "    df.loc[not_null_mask, col] = le.fit_transform(df.loc[not_null_mask, col].astype(str))\n",
    "    encoders[col] = le\n",
    "\n",
    "# Use KNN to impute the missing values\n",
    "knn_imputer = KNN()\n",
    "df_imputed = knn_imputer.fit_transform(df)\n",
    "\n",
    "# Round imputed values and convert to int for decoding\n",
    "# Note that the rounding is necessary because NaNs force columns to become floats\n",
    "df_imputed = pd.DataFrame(np.round(df_imputed), columns=df.columns).astype(int)\n",
    "\n",
    "# Decode imputed values back to original categorical values\n",
    "for col in df.columns:\n",
    "    df_imputed[col] = encoders[col].inverse_transform(df_imputed[col])\n",
    "\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other strategies may be applied in a similar manner, after which you can one-hot encode your data, and proceed with additional processing!\n",
    "\n",
    "Note that there is currently no elegant solution for imputation of categorical variables, and so if you want something more sophisticated than a SimpleImputer with a \"most_frequent\" strategy, you'll probably need to write some code.  However, we can turn the above method into our own \"Imputer\" class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from fancyimpute import KNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CategoricalKNNImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, include_numeric=False, include_cols = []):\n",
    "        self.encoders = {}\n",
    "        self.knn_imputer = KNN()\n",
    "        self.include_numeric = include_numeric\n",
    "        self.include_cols = include_cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if self.include_numeric:\n",
    "            self.cols = X.columns.tolist()\n",
    "        else:\n",
    "            self.cols = X.select_dtypes(include=['object', 'category']).columns.tolist()+self.include_cols\n",
    "            \n",
    "        for col in self.cols:\n",
    "            le = LabelEncoder()\n",
    "            not_null_mask = X[col].notnull()\n",
    "            if not_null_mask.sum() > 0:  # Only if there are non-null values to fit\n",
    "                X.loc[not_null_mask, col] = le.fit_transform(X.loc[not_null_mask, col].astype(str))\n",
    "                self.encoders[col] = le\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_original = X.copy()\n",
    "        X = X.copy()\n",
    "        \n",
    "        for col in self.cols:\n",
    "            if col in self.encoders:  # Only if encoder exists\n",
    "                not_null_mask = X[col].notnull()\n",
    "                X.loc[not_null_mask, col] = self.encoders[col].transform(X.loc[not_null_mask, col].astype(str))\n",
    "        \n",
    "        X_imputed = self.knn_imputer.fit_transform(X)\n",
    "        X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "        \n",
    "        for col in self.cols:\n",
    "            if col in self.encoders:  # Only if encoder exists\n",
    "                X_imputed.loc[:, col] = np.round(X_imputed.loc[:, col])  # Rounding only categorical columns\n",
    "                X_imputed[col] = X_imputed[col].astype(int)  # Converting to int before decoding\n",
    "                X_imputed[col] = self.encoders[col].inverse_transform(X_imputed[col])\n",
    "        \n",
    "        if not self.include_numeric:\n",
    "            replacements = [x for x in X.columns if x not in self.cols]\n",
    "            #numeric_cols = X_original.select_dtypes(include=[np.number]).columns\n",
    "            X_imputed[replacements] = X_original[replacements]\n",
    "        \n",
    "        return X_imputed\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
